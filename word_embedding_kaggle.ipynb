{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import one_hot,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences #converts all documents onto same length\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Input,Embedding\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Documents\n",
    "sample_txt1 = \"bitty bought a bit of butter\"\n",
    "sample_txt2 = \"but the bit of butter was a bit bitter\"\n",
    "sample_txt3 = \"so she bought some better butter to make the bitter butter better\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bitty bought a bit of butter', 'but the bit of butter was a bit bitter', 'so she bought some better butter to make the bitter butter better']\n"
     ]
    }
   ],
   "source": [
    "corpus = [sample_txt1,sample_txt2,sample_txt3]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one_hot encoding for documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The encoding for document 1 is [13, 22, 40, 30, 31, 5]\n",
      " The encoding for document 2 is [27, 43, 30, 31, 5, 20, 40, 30, 45]\n",
      " The encoding for document 3 is [14, 32, 22, 4, 1, 5, 36, 33, 43, 45, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "voacb_size = 50 #length\n",
    "encod_corpus = []\n",
    "for i, doc in enumerate(corpus):\n",
    "    encod_corpus.append(one_hot(doc,50))\n",
    "    print(\" The encoding for document\",i+1,\"is\",one_hot(doc,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[13, 22, 40, 30, 31, 5],\n",
       " [27, 43, 30, 31, 5, 20, 40, 30, 45],\n",
       " [14, 32, 22, 4, 1, 5, 36, 33, 43, 45, 5, 1]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encod_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PADDING THE DOCS (to make very doc of same length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=-1\n",
    "for doc in corpus:\n",
    "    tokens = nltk.word_tokenize(doc)#convertng sentence into tokens(words) \n",
    "    if(maxlen<len(tokens)):\n",
    "        maxlen = len(tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max no of words in a document is :  12\n"
     ]
    }
   ],
   "source": [
    "print(\"The max no of words in a document is : \",maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of padded documents :  3\n"
     ]
    }
   ],
   "source": [
    "# now to create embeddings all of our docs need to be of same length. hence we can pad the docs with zeros.\n",
    "\n",
    "pad_corp = pad_sequences(encod_corpus,maxlen = maxlen,padding = 'post',value = 0.0) #adding 0 values to post index\n",
    "print(\"No of padded documents : \",len(pad_corp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 22, 40, 30, 31,  5,  0,  0,  0,  0,  0,  0],\n",
       "       [27, 43, 30, 31,  5, 20, 40, 30, 45,  0,  0,  0],\n",
       "       [14, 32, 22,  4,  1,  5, 36, 33, 43, 45,  5,  1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The padded encoding for document  1  is :  [13 22 40 30 31  5  0  0  0  0  0  0]\n",
      "The padded encoding for document  2  is :  [27 43 30 31  5 20 40 30 45  0  0  0]\n",
      "The padded encoding for document  3  is :  [14 32 22  4  1  5 36 33 43 45  5  1]\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(pad_corp):\n",
    "    print(\"The padded encoding for document \",i+1,\" is : \",doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING THE EMBEDDINGS using KERAS EMBEDDING LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Now all the documents are of same length (after padding). And so now we are ready to create and use the embeddings.\n",
    "# I will embed the words into vectors of 8 dimensions.\n",
    "\n",
    "no_docs = len(corpus)\n",
    "print(no_docs)\n",
    "\n",
    "# each document has 12 element or words which is the value of our maxlen variable.\n",
    "\n",
    "input = Input(shape = (no_docs,maxlen),dtype = 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_input = Input(shape = (maxlen,),dtype = 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the embedding\n",
    "word_embedding = Embedding(input_dim = voacb_size,output_dim = 8,input_length = maxlen)(word_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"embedding_2/embedding_lookup/Identity:0\", shape=(?, 12, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(type(word_embedding))\n",
    "print(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"flatten_2/Reshape:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#word2vec flatten\n",
    "word_vec = Flatten()(word_embedding)\n",
    "print(word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x000001CDCF348188>\n"
     ]
    }
   ],
   "source": [
    "#model combining all into a Keras model\n",
    "embed_model = Model([word_input],word_vec)\n",
    "print(embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model. \n",
    "embed_model.compile(optimizer = keras.optimizers.Adam(lr = 1e-3),loss = 'binary_crossentropy',metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 12, 8)             400       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 96)                0         \n",
      "=================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(embed_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of embeddings (3, 96)\n",
      "[[ 0.00422787 -0.03559115 -0.03359684 -0.03900168 -0.0229318  -0.00882538\n",
      "  -0.0030782   0.01571907  0.04736512 -0.00540179 -0.02613487 -0.03620505\n",
      "   0.0182913  -0.01811811 -0.03259911  0.01811392 -0.04593556  0.00836105\n",
      "  -0.00622425  0.04533401 -0.04631129 -0.00973624 -0.02185645  0.01667226\n",
      "   0.04427114 -0.02009405  0.01680804  0.04458213 -0.00809828  0.00193854\n",
      "   0.04426659  0.0203527   0.03442018 -0.01509865  0.01738982  0.00976884\n",
      "  -0.03131445  0.04668872 -0.01860714 -0.02274306  0.03158749  0.00219008\n",
      "   0.00839042 -0.03041352  0.03101322 -0.04996213 -0.04922906  0.04721412\n",
      "   0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979  0.00558069\n",
      "   0.03871623 -0.01093327  0.00263207  0.00624193 -0.01942141 -0.02046084\n",
      "   0.04805979  0.00558069  0.03871623 -0.01093327  0.00263207  0.00624193\n",
      "  -0.01942141 -0.02046084  0.04805979  0.00558069  0.03871623 -0.01093327\n",
      "   0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979  0.00558069\n",
      "   0.03871623 -0.01093327  0.00263207  0.00624193 -0.01942141 -0.02046084\n",
      "   0.04805979  0.00558069  0.03871623 -0.01093327  0.00263207  0.00624193\n",
      "  -0.01942141 -0.02046084  0.04805979  0.00558069  0.03871623 -0.01093327]\n",
      " [-0.03953515 -0.01710797 -0.02170872  0.04469461 -0.04900701 -0.00810313\n",
      "   0.00710599  0.00578232 -0.0351017   0.01086229 -0.04731505  0.03875995\n",
      "  -0.01380109  0.02068857 -0.02084429 -0.02624229  0.04427114 -0.02009405\n",
      "   0.01680804  0.04458213 -0.00809828  0.00193854  0.04426659  0.0203527\n",
      "   0.03442018 -0.01509865  0.01738982  0.00976884 -0.03131445  0.04668872\n",
      "  -0.01860714 -0.02274306  0.03158749  0.00219008  0.00839042 -0.03041352\n",
      "   0.03101322 -0.04996213 -0.04922906  0.04721412  0.04801246  0.03742928\n",
      "  -0.02321343  0.02020074 -0.01686777  0.02315248  0.02292073  0.00571741\n",
      "  -0.04593556  0.00836105 -0.00622425  0.04533401 -0.04631129 -0.00973624\n",
      "  -0.02185645  0.01667226  0.04427114 -0.02009405  0.01680804  0.04458213\n",
      "  -0.00809828  0.00193854  0.04426659  0.0203527  -0.02582154 -0.00048538\n",
      "   0.0296892   0.00905458 -0.00286186  0.03569604 -0.029628    0.0020274\n",
      "   0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979  0.00558069\n",
      "   0.03871623 -0.01093327  0.00263207  0.00624193 -0.01942141 -0.02046084\n",
      "   0.04805979  0.00558069  0.03871623 -0.01093327  0.00263207  0.00624193\n",
      "  -0.01942141 -0.02046084  0.04805979  0.00558069  0.03871623 -0.01093327]\n",
      " [ 0.00779026  0.01119962  0.02142315  0.00731393 -0.04428897  0.00492846\n",
      "  -0.02754948 -0.0361487   0.04445401 -0.0026773  -0.00011189 -0.0230772\n",
      "  -0.04492318 -0.04965295  0.0099906  -0.03171854  0.04736512 -0.00540179\n",
      "  -0.02613487 -0.03620505  0.0182913  -0.01811811 -0.03259911  0.01811392\n",
      "   0.01625725  0.014196    0.01474353  0.04168484 -0.00736424  0.02131155\n",
      "   0.01148508  0.03686709  0.04461269 -0.03461269 -0.03150449  0.02718605\n",
      "   0.03008372  0.00451901 -0.02099423  0.0035098   0.03158749  0.00219008\n",
      "   0.00839042 -0.03041352  0.03101322 -0.04996213 -0.04922906  0.04721412\n",
      "   0.01326387 -0.03536328  0.00491444  0.03589057  0.03536778  0.0418389\n",
      "   0.02117281 -0.02803903 -0.00699021  0.03878191  0.03913686 -0.02598563\n",
      "   0.00767989  0.00744992  0.04873984 -0.01577763 -0.0351017   0.01086229\n",
      "  -0.04731505  0.03875995 -0.01380109  0.02068857 -0.02084429 -0.02624229\n",
      "  -0.02582154 -0.00048538  0.0296892   0.00905458 -0.00286186  0.03569604\n",
      "  -0.029628    0.0020274   0.03158749  0.00219008  0.00839042 -0.03041352\n",
      "   0.03101322 -0.04996213 -0.04922906  0.04721412  0.04461269 -0.03461269\n",
      "  -0.03150449  0.02718605  0.03008372  0.00451901 -0.02099423  0.0035098 ]]\n"
     ]
    }
   ],
   "source": [
    "# finally getting the embeddings.\n",
    "embeddings = embed_model.predict(pad_corp)\n",
    "print(\"shape of embeddings\",embeddings.shape)\n",
    "print(embeddings)\n",
    "\n",
    "# 3 documents \n",
    "# 1 document 12 words and 8 dimensions = 96 vectors for one document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The resulting shape is (3,12,8).\n",
    "\n",
    "3---> no of documents\n",
    "\n",
    "12---> each document is made of 12 words which was our maximum length of any document.\n",
    "\n",
    "& 8---> each word is 8 dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (3, 12, 8)\n",
      "[[[ 0.00422787 -0.03559115 -0.03359684 -0.03900168 -0.0229318\n",
      "   -0.00882538 -0.0030782   0.01571907]\n",
      "  [ 0.04736512 -0.00540179 -0.02613487 -0.03620505  0.0182913\n",
      "   -0.01811811 -0.03259911  0.01811392]\n",
      "  [-0.04593556  0.00836105 -0.00622425  0.04533401 -0.04631129\n",
      "   -0.00973624 -0.02185645  0.01667226]\n",
      "  [ 0.04427114 -0.02009405  0.01680804  0.04458213 -0.00809828\n",
      "    0.00193854  0.04426659  0.0203527 ]\n",
      "  [ 0.03442018 -0.01509865  0.01738982  0.00976884 -0.03131445\n",
      "    0.04668872 -0.01860714 -0.02274306]\n",
      "  [ 0.03158749  0.00219008  0.00839042 -0.03041352  0.03101322\n",
      "   -0.04996213 -0.04922906  0.04721412]\n",
      "  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979\n",
      "    0.00558069  0.03871623 -0.01093327]\n",
      "  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979\n",
      "    0.00558069  0.03871623 -0.01093327]\n",
      "  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979\n",
      "    0.00558069  0.03871623 -0.01093327]\n",
      "  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979\n",
      "    0.00558069  0.03871623 -0.01093327]\n",
      "  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979\n",
      "    0.00558069  0.03871623 -0.01093327]\n",
      "  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979\n",
      "    0.00558069  0.03871623 -0.01093327]]\n",
      "\n",
      " [[-0.03953515 -0.01710797 -0.02170872  0.04469461 -0.04900701\n",
      "   -0.00810313  0.00710599  0.00578232]\n",
      "  [-0.0351017   0.01086229 -0.04731505  0.03875995 -0.01380109\n",
      "    0.02068857 -0.02084429 -0.02624229]\n",
      "  [ 0.04427114 -0.02009405  0.01680804  0.04458213 -0.00809828\n",
      "    0.00193854  0.04426659  0.0203527 ]\n",
      "  [ 0.03442018 -0.01509865  0.01738982  0.00976884 -0.03131445\n",
      "    0.04668872 -0.01860714 -0.02274306]\n",
      "  [ 0.03158749  0.00219008  0.00839042 -0.03041352  0.03101322\n",
      "   -0.04996213 -0.04922906  0.04721412]\n",
      "  [ 0.04801246  0.03742928 -0.02321343  0.02020074 -0.01686777\n",
      "    0.02315248  0.02292073  0.00571741]\n",
      "  [-0.04593556  0.00836105 -0.00622425  0.04533401 -0.04631129\n",
      "   -0.00973624 -0.02185645  0.01667226]\n",
      "  [ 0.04427114 -0.02009405  0.01680804  0.04458213 -0.00809828\n",
      "    0.00193854  0.04426659  0.0203527 ]\n",
      "  [-0.02582154 -0.00048538  0.0296892   0.00905458 -0.00286186\n",
      "    0.03569604 -0.029628    0.0020274 ]\n",
      "  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979\n",
      "    0.00558069  0.03871623 -0.01093327]\n",
      "  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979\n",
      "    0.00558069  0.03871623 -0.01093327]\n",
      "  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979\n",
      "    0.00558069  0.03871623 -0.01093327]]\n",
      "\n",
      " [[ 0.00779026  0.01119962  0.02142315  0.00731393 -0.04428897\n",
      "    0.00492846 -0.02754948 -0.0361487 ]\n",
      "  [ 0.04445401 -0.0026773  -0.00011189 -0.0230772  -0.04492318\n",
      "   -0.04965295  0.0099906  -0.03171854]\n",
      "  [ 0.04736512 -0.00540179 -0.02613487 -0.03620505  0.0182913\n",
      "   -0.01811811 -0.03259911  0.01811392]\n",
      "  [ 0.01625725  0.014196    0.01474353  0.04168484 -0.00736424\n",
      "    0.02131155  0.01148508  0.03686709]\n",
      "  [ 0.04461269 -0.03461269 -0.03150449  0.02718605  0.03008372\n",
      "    0.00451901 -0.02099423  0.0035098 ]\n",
      "  [ 0.03158749  0.00219008  0.00839042 -0.03041352  0.03101322\n",
      "   -0.04996213 -0.04922906  0.04721412]\n",
      "  [ 0.01326387 -0.03536328  0.00491444  0.03589057  0.03536778\n",
      "    0.0418389   0.02117281 -0.02803903]\n",
      "  [-0.00699021  0.03878191  0.03913686 -0.02598563  0.00767989\n",
      "    0.00744992  0.04873984 -0.01577763]\n",
      "  [-0.0351017   0.01086229 -0.04731505  0.03875995 -0.01380109\n",
      "    0.02068857 -0.02084429 -0.02624229]\n",
      "  [-0.02582154 -0.00048538  0.0296892   0.00905458 -0.00286186\n",
      "    0.03569604 -0.029628    0.0020274 ]\n",
      "  [ 0.03158749  0.00219008  0.00839042 -0.03041352  0.03101322\n",
      "   -0.04996213 -0.04922906  0.04721412]\n",
      "  [ 0.04461269 -0.03461269 -0.03150449  0.02718605  0.03008372\n",
      "    0.00451901 -0.02099423  0.0035098 ]]]\n"
     ]
    }
   ],
   "source": [
    "embeddings = embeddings.reshape(-1,maxlen,8)\n",
    "print(\"shape\",embeddings.shape)# 3 rows 12 words 8 dimensions\n",
    "print(embeddings) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GETTING ENCODING FOR A PARTICULAR WORD IN A SPECIFIC DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoding for  1 th word in  1 document  [ 0.00422787 -0.03559115 -0.03359684 -0.03900168 -0.0229318  -0.00882538\n",
      " -0.0030782   0.01571907]\n",
      "The encoding for  2 th word in  1 document  [ 0.04736512 -0.00540179 -0.02613487 -0.03620505  0.0182913  -0.01811811\n",
      " -0.03259911  0.01811392]\n",
      "The encoding for  3 th word in  1 document  [-0.04593556  0.00836105 -0.00622425  0.04533401 -0.04631129 -0.00973624\n",
      " -0.02185645  0.01667226]\n",
      "The encoding for  4 th word in  1 document  [ 0.04427114 -0.02009405  0.01680804  0.04458213 -0.00809828  0.00193854\n",
      "  0.04426659  0.0203527 ]\n",
      "The encoding for  5 th word in  1 document  [ 0.03442018 -0.01509865  0.01738982  0.00976884 -0.03131445  0.04668872\n",
      " -0.01860714 -0.02274306]\n",
      "The encoding for  6 th word in  1 document  [ 0.03158749  0.00219008  0.00839042 -0.03041352  0.03101322 -0.04996213\n",
      " -0.04922906  0.04721412]\n",
      "The encoding for  7 th word in  1 document  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979  0.00558069\n",
      "  0.03871623 -0.01093327]\n",
      "The encoding for  8 th word in  1 document  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979  0.00558069\n",
      "  0.03871623 -0.01093327]\n",
      "The encoding for  9 th word in  1 document  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979  0.00558069\n",
      "  0.03871623 -0.01093327]\n",
      "The encoding for  10 th word in  1 document  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979  0.00558069\n",
      "  0.03871623 -0.01093327]\n",
      "The encoding for  11 th word in  1 document  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979  0.00558069\n",
      "  0.03871623 -0.01093327]\n",
      "The encoding for  12 th word in  1 document  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979  0.00558069\n",
      "  0.03871623 -0.01093327]\n",
      "The encoding for  1 th word in  2 document  [-0.03953515 -0.01710797 -0.02170872  0.04469461 -0.04900701 -0.00810313\n",
      "  0.00710599  0.00578232]\n",
      "The encoding for  2 th word in  2 document  [-0.0351017   0.01086229 -0.04731505  0.03875995 -0.01380109  0.02068857\n",
      " -0.02084429 -0.02624229]\n",
      "The encoding for  3 th word in  2 document  [ 0.04427114 -0.02009405  0.01680804  0.04458213 -0.00809828  0.00193854\n",
      "  0.04426659  0.0203527 ]\n",
      "The encoding for  4 th word in  2 document  [ 0.03442018 -0.01509865  0.01738982  0.00976884 -0.03131445  0.04668872\n",
      " -0.01860714 -0.02274306]\n",
      "The encoding for  5 th word in  2 document  [ 0.03158749  0.00219008  0.00839042 -0.03041352  0.03101322 -0.04996213\n",
      " -0.04922906  0.04721412]\n",
      "The encoding for  6 th word in  2 document  [ 0.04801246  0.03742928 -0.02321343  0.02020074 -0.01686777  0.02315248\n",
      "  0.02292073  0.00571741]\n",
      "The encoding for  7 th word in  2 document  [-0.04593556  0.00836105 -0.00622425  0.04533401 -0.04631129 -0.00973624\n",
      " -0.02185645  0.01667226]\n",
      "The encoding for  8 th word in  2 document  [ 0.04427114 -0.02009405  0.01680804  0.04458213 -0.00809828  0.00193854\n",
      "  0.04426659  0.0203527 ]\n",
      "The encoding for  9 th word in  2 document  [-0.02582154 -0.00048538  0.0296892   0.00905458 -0.00286186  0.03569604\n",
      " -0.029628    0.0020274 ]\n",
      "The encoding for  10 th word in  2 document  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979  0.00558069\n",
      "  0.03871623 -0.01093327]\n",
      "The encoding for  11 th word in  2 document  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979  0.00558069\n",
      "  0.03871623 -0.01093327]\n",
      "The encoding for  12 th word in  2 document  [ 0.00263207  0.00624193 -0.01942141 -0.02046084  0.04805979  0.00558069\n",
      "  0.03871623 -0.01093327]\n",
      "The encoding for  1 th word in  3 document  [ 0.00779026  0.01119962  0.02142315  0.00731393 -0.04428897  0.00492846\n",
      " -0.02754948 -0.0361487 ]\n",
      "The encoding for  2 th word in  3 document  [ 0.04445401 -0.0026773  -0.00011189 -0.0230772  -0.04492318 -0.04965295\n",
      "  0.0099906  -0.03171854]\n",
      "The encoding for  3 th word in  3 document  [ 0.04736512 -0.00540179 -0.02613487 -0.03620505  0.0182913  -0.01811811\n",
      " -0.03259911  0.01811392]\n",
      "The encoding for  4 th word in  3 document  [ 0.01625725  0.014196    0.01474353  0.04168484 -0.00736424  0.02131155\n",
      "  0.01148508  0.03686709]\n",
      "The encoding for  5 th word in  3 document  [ 0.04461269 -0.03461269 -0.03150449  0.02718605  0.03008372  0.00451901\n",
      " -0.02099423  0.0035098 ]\n",
      "The encoding for  6 th word in  3 document  [ 0.03158749  0.00219008  0.00839042 -0.03041352  0.03101322 -0.04996213\n",
      " -0.04922906  0.04721412]\n",
      "The encoding for  7 th word in  3 document  [ 0.01326387 -0.03536328  0.00491444  0.03589057  0.03536778  0.0418389\n",
      "  0.02117281 -0.02803903]\n",
      "The encoding for  8 th word in  3 document  [-0.00699021  0.03878191  0.03913686 -0.02598563  0.00767989  0.00744992\n",
      "  0.04873984 -0.01577763]\n",
      "The encoding for  9 th word in  3 document  [-0.0351017   0.01086229 -0.04731505  0.03875995 -0.01380109  0.02068857\n",
      " -0.02084429 -0.02624229]\n",
      "The encoding for  10 th word in  3 document  [-0.02582154 -0.00048538  0.0296892   0.00905458 -0.00286186  0.03569604\n",
      " -0.029628    0.0020274 ]\n",
      "The encoding for  11 th word in  3 document  [ 0.03158749  0.00219008  0.00839042 -0.03041352  0.03101322 -0.04996213\n",
      " -0.04922906  0.04721412]\n",
      "The encoding for  12 th word in  3 document  [ 0.04461269 -0.03461269 -0.03150449  0.02718605  0.03008372  0.00451901\n",
      " -0.02099423  0.0035098 ]\n"
     ]
    }
   ],
   "source": [
    "for i ,doc in enumerate(embeddings):\n",
    "    for j ,word in enumerate(doc):\n",
    "        print(\"The encoding for \",j+1,\"th word in \",i+1,\"document \",word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'bitty bought a bit of butter')\n",
      "(1, 'but the bit of butter was a bit bitter')\n",
      "(2, 'so she bought some better butter to make the bitter butter better')\n",
      "0 bitty bought a bit of butter\n",
      "1 but the bit of butter was a bit bitter\n",
      "2 so she bought some better butter to make the bitter butter better\n"
     ]
    }
   ],
   "source": [
    "#extra stuff\n",
    "for doc in enumerate(corpus):\n",
    "    print(doc)\n",
    "#differences between both\n",
    "for i,doc in enumerate(corpus):\n",
    "    print(i,doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
